{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335da2a9",
   "metadata": {},
   "source": [
    "# Imports, constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af610a01",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import radiomics as pr\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from radiomics import featureextractor\n",
    "from sklearn.linear_model import lasso_path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.ndimage import binary_dilation, binary_erosion\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e107a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "INPUT_PATH = '/Users/veramegias/Documents/Universidad/Cuarto/TFG/Segmentaciones'\n",
    "IMAGES_PATH = 'images'\n",
    "OUTPUT_PATH = 'outputs'\n",
    "REEXECUTE = True\n",
    "MAX_NUM = 43\n",
    "\n",
    "columns_file_text = f'{OUTPUT_PATH}/columnas_df_features.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb894471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df, label_column, threshold_corr=0.95, threshold_var=0.01):\n",
    "    \"\"\"\n",
    "    Preprocesa un DataFrame eliminando variables constantes, colineales y normalizando los datos.\n",
    "\n",
    "    Pasos:\n",
    "        1. Separa las variables independientes (X) y la variable objetivo (y).\n",
    "        2. Elimina variables con baja varianza (prácticamente constantes).\n",
    "        3. Elimina variables con alta correlación para reducir colinealidad.\n",
    "        4. Normaliza las características con StandardScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con las características radiómicas y la columna de la variable objetivo.\n",
    "        label_column (str): Nombre de la columna que contiene la variable objetivo.\n",
    "        threshold_corr (float): Umbral de correlación para eliminar variables (default 0.95).\n",
    "        threshold_var (float): Umbral de varianza mínima para eliminar variables constantes (default 0.01).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con las características preprocesadas, filtradas y normalizadas.\n",
    "        pd.Series: Variable objetivo (y).\n",
    "        list: Lista de variables eliminadas.\n",
    "    \"\"\"\n",
    "    n_variables = len(df.columns)\n",
    "    # 1. Separar la variable objetivo (y) de las características (X)\n",
    "    X = df.drop(columns=[label_column])  # Todas las columnas excepto la de la etiqueta\n",
    "    y = df[label_column]                 # Columna de la variable objetivo\n",
    "    \n",
    "    # 2. Eliminar variables con baja varianza\n",
    "    var_selector = VarianceThreshold(threshold=threshold_var)\n",
    "    X_var_filtered = pd.DataFrame(var_selector.fit_transform(X), columns=X.columns[var_selector.get_support()])\n",
    "    removed_low_var = list(set(X.columns) - set(X_var_filtered.columns))\n",
    "    \n",
    "    print(f\"Se eliminaron {len(removed_low_var)} variables con baja varianza.\")\n",
    "\n",
    "    # 3. Eliminar variables altamente correlacionadas\n",
    "    corr_matrix = X_var_filtered.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold_corr)]\n",
    "    \n",
    "    X_filtered = X_var_filtered.drop(columns=to_drop)\n",
    "    \n",
    "    print(f\"Se eliminaron {len(to_drop)} variables altamente correlacionadas.\")\n",
    "\n",
    "    # 4. Normalizar las características con StandardScaler y devolverlo como DataFrame\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X_filtered), columns=X_filtered.columns, index=X.index)\n",
    "    \n",
    "    print(f'Se han eliminado {len(removed_low_var + to_drop)} de {n_variables} variables')\n",
    "\n",
    "    return X_scaled, y, removed_low_var + to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c8c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(df):\n",
    "    \"\"\"\n",
    "    Transforma un DataFrame con celdas de diferentes clases a numeros o strings.\n",
    "    \n",
    "    Para columnas que contienen listas o tuplas:\n",
    "    - Si la lista o tupla tiene un único elemento, convierte el valor en un número o string según corresponda.\n",
    "    - Si la lista o tupla tiene múltiples elementos, expande la columna en varias columnas, \n",
    "      una por cada elemento de la lista o tupla. Las nuevas columnas se nombran usando el nombre \n",
    "      original seguido por un sufijo `_1`, `_2`, etc.\n",
    "\n",
    "    Para columnas que contienen diccionarios:\n",
    "    - Cada clave del diccionario se convierte en una nueva columna.\n",
    "    - Si un valor del diccionario es un array/lista o tupla:\n",
    "        - Si tiene un único elemento, se convierte en un valor único.\n",
    "        - Si tiene múltiples elementos, genera columnas adicionales con sufijos `_1`, `_2`, etc.\n",
    "    - Las nuevas columnas se nombran usando el nombre original seguido por `_{key}` y, si es necesario, \n",
    "      un sufijo adicional para los arrays o tuplas.\n",
    "    - Elimina la columna original una vez procesada.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original.\n",
    "    Returns:\n",
    "        df (pd.DataFrame): DataFrame transformado.\n",
    "    \"\"\"\n",
    "    # Crear una copia para no modificar el original\n",
    "    transformed_df = df.copy()\n",
    "\n",
    "    # Iterar sobre las columnas\n",
    "    for col in transformed_df.columns:\n",
    "        # Identificar las celdas que son listas, tuplas o arrays\n",
    "        if transformed_df[col].apply(lambda x: isinstance(x, (list, tuple))).any():\n",
    "            # Expandir los valores si hay listas/tuplas con más de un elemento\n",
    "            expanded = transformed_df[col].apply(lambda x: list(x) if isinstance(x, (list, tuple)) else [x])\n",
    "            \n",
    "            # Verificar la longitud máxima de las listas/tuplas\n",
    "            max_len = expanded.apply(len).max()\n",
    "            \n",
    "            if max_len > 1:\n",
    "                # Crear nuevas columnas para listas/tuplas con múltiples elementos\n",
    "                for i in range(max_len):\n",
    "                    transformed_df[f\"{col}_{i+1}\"] = expanded.apply(lambda x: x[i] if i < len(x) else None)\n",
    "                \n",
    "                # Eliminar la columna original\n",
    "                transformed_df.drop(columns=[col], inplace=True)\n",
    "            else:\n",
    "                # Convertir listas/tuplas con un único elemento en valores (número o string)\n",
    "                transformed_df[col] = expanded.apply(lambda x: x[0] if len(x) == 1 else x)\n",
    "        \n",
    "        # Identificar las celdas que son diccionarios\n",
    "        elif transformed_df[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "            # Expandir las claves del diccionario en nuevas columnas\n",
    "            dict_expansion = transformed_df[col].apply(lambda x: x if isinstance(x, dict) else {})\n",
    "            keys = set(k for d in dict_expansion for k in d.keys())\n",
    "            \n",
    "            for key in keys:\n",
    "                # Extraer los valores de la clave específica\n",
    "                key_values = dict_expansion.apply(lambda x: x.get(key, None))\n",
    "                \n",
    "                # Si los valores son arrays, listas o tuplas, manejarlos como tal\n",
    "                if key_values.apply(lambda x: isinstance(x, (list, tuple))).any():\n",
    "                    # Expandir los arrays/tuplas en columnas adicionales\n",
    "                    expanded = key_values.apply(lambda x: list(x) if isinstance(x, (list, tuple)) else [x])\n",
    "                    max_len = expanded.apply(len).max()\n",
    "                    \n",
    "                    for i in range(max_len):\n",
    "                        transformed_df[f\"{col}_{key}_{i+1}\"] = expanded.apply(lambda x: x[i] if i < len(x) else None)\n",
    "                else:\n",
    "                    # Si no son listas/tuplas, mantener el valor tal cual\n",
    "                    transformed_df[f\"{col}_{key}\"] = key_values\n",
    "            \n",
    "            # Eliminar la columna original\n",
    "            transformed_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aad380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_sizes(image1, image2):\n",
    "    \"\"\"\n",
    "    Comprueba que la imagen 1 y la imagen 1 tienen las mismas dimensiones.\n",
    "    Args:\n",
    "        image1 (SimpleITK.Image): Imagen 1.\n",
    "        image2 (SimpleITK.Image): Imagen 2.\n",
    "    Returns:\n",
    "        boolean: Si el tamaño coincide\n",
    "    \"\"\"\n",
    "    return image1.GetSize() == image2.GetSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32a7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_resegmentation(mask, method='dilation', iterations=1):\n",
    "    \"\"\"\n",
    "    Simula una segunda segmentación modificando la máscara original.\n",
    "    \n",
    "    Parámetros:\n",
    "        mask (sitk.Image): Máscara original.\n",
    "        method (str): 'dilation' o 'erosion'. Se usa para simular una resegmentación.\n",
    "        iterations (int): Número de iteraciones de la operación morfológica.\n",
    "    \n",
    "    Retorna:\n",
    "        sitk.Image: Máscara modificada.\n",
    "    \"\"\"\n",
    "    mask_arr = sitk.GetArrayFromImage(mask)\n",
    "    \n",
    "    if method == 'dilation':\n",
    "        mask_arr_mod = binary_dilation(mask_arr, structure=np.ones((3,3,3)), iterations=iterations)\n",
    "    elif method == 'erosion':\n",
    "        mask_arr_mod = binary_erosion(mask_arr, structure=np.ones((3,3,3)), iterations=iterations)\n",
    "    else:\n",
    "        raise ValueError(\"El método debe ser 'dilation' o 'erosion'\")\n",
    "    \n",
    "    mask_mod = sitk.GetImageFromArray(mask_arr_mod.astype(np.uint8))\n",
    "    mask_mod.CopyInformation(mask)\n",
    "    return mask_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d58d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_interpolation(image, new_spacing):\n",
    "    \"\"\"\n",
    "    Re-muestrea la imagen a un espaciamiento ligeramente modificado.\n",
    "    \n",
    "    Parámetros:\n",
    "        image (sitk.Image): Imagen original.\n",
    "        new_spacing (tuple): Nuevo espaciamiento (por ejemplo, (sx, sy, sz)).\n",
    "    \n",
    "    Retorna:\n",
    "        sitk.Image: Imagen re-muestreada.\n",
    "    \"\"\"\n",
    "    original_spacing = image.GetSpacing()\n",
    "    original_size = image.GetSize()\n",
    "    new_size = [int(round(osz * ospc / nspc)) for osz, ospc, nspc in zip(original_size, original_spacing, new_spacing)]\n",
    "    \n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(new_spacing)\n",
    "    resample.SetSize(new_size)\n",
    "    resample.SetOutputDirection(image.GetDirection())\n",
    "    resample.SetOutputOrigin(image.GetOrigin())\n",
    "    resample.SetInterpolator(sitk.sitkLinear)\n",
    "    new_image = resample.Execute(image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce2f6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_interpolation_mask(mask, new_spacing):\n",
    "    \"\"\"\n",
    "    Re-muestrea la máscara (usando interpolación de vecino más cercano) a un espaciamiento modificado.\n",
    "    \n",
    "    Parámetros:\n",
    "        mask (sitk.Image): Máscara original.\n",
    "        new_spacing (tuple): Nuevo espaciamiento.\n",
    "    \n",
    "    Retorna:\n",
    "        sitk.Image: Máscara re-muestreada.\n",
    "    \"\"\"\n",
    "    original_spacing = mask.GetSpacing()\n",
    "    original_size = mask.GetSize()\n",
    "    new_size = [int(round(osz * ospc / nspc)) for osz, ospc, nspc in zip(original_size, original_spacing, new_spacing)]\n",
    "    \n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(new_spacing)\n",
    "    resample.SetSize(new_size)\n",
    "    resample.SetOutputDirection(mask.GetDirection())\n",
    "    resample.SetOutputOrigin(mask.GetOrigin())\n",
    "    resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    new_mask = resample.Execute(mask)\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eacbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image, mask):\n",
    "    if same_sizes(image, mask):\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "    else:\n",
    "        print(f'[ERROR] Sizes are not the same.')\n",
    "    features = extractor.execute(image, mask)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02c08045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_file_path, mask_file_path, process_type):\n",
    "    \"\"\"\n",
    "    Extrae características radiómicas de una imagen y su máscara utilizando PyRadiomics.\n",
    "    Args:\n",
    "        image_file_path (str): Ruta al archivo NRRD que contiene la imagen a analizar.\n",
    "        mask_file_path (str): Ruta al archivo NRRD que contiene la máscara asociada a la imagen.\n",
    "    Returns:\n",
    "        features (dict): Características radiómicas extraídas.\n",
    "    Extra:\n",
    "        Comprueba que el tamaño de las imagenes sea compatible.\n",
    "    \"\"\"\n",
    "    # Load paths and images\n",
    "    image_data, _ = nrrd.read(image_file_path)\n",
    "    image = sitk.GetImageFromArray(image_data)\n",
    "    mask_data, _ = nrrd.read(mask_file_path)\n",
    "    mask = sitk.GetImageFromArray(mask_data)\n",
    "\n",
    "    if process_type == \"resegmentation\":\n",
    "        mask = simulate_resegmentation(mask, method='dilation', iterations=1)\n",
    "    elif process_type == \"interpolation\":\n",
    "        original_spacing = image.GetSpacing()\n",
    "        new_spacing = tuple([s + 0.1 for s in original_spacing])\n",
    "        image = simulate_interpolation(image, new_spacing)\n",
    "        mask  = simulate_interpolation_mask(mask, new_spacing)\n",
    "    elif process_type == \"original\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"[ERROR]  No valid process. Nothing applied.\")\n",
    "\n",
    "    return get_features(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "115644fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns_to_numeric(df):\n",
    "    \"\"\"\n",
    "    Intenta convertir todas las columnas de un DataFrame a valores numéricos, \n",
    "    incluyendo la transformación de booleanos a numéricos.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original.\n",
    "    Returns:\n",
    "        df (pd.DataFrame): DataFrame transformado.\n",
    "    \"\"\"\n",
    "    # Crear una copia del DataFrame para no modificar el original\n",
    "    numeric_df = df.copy()\n",
    "    \n",
    "    for col in numeric_df.columns:\n",
    "        try:\n",
    "            # Convertir booleanos a numéricos explícitamente\n",
    "            if numeric_df[col].dtype == 'bool':\n",
    "                numeric_df[col] = numeric_df[col].astype(int)\n",
    "            \n",
    "            # Intentar convertir la columna a valores numéricos\n",
    "            numeric_df[col] = pd.to_numeric(numeric_df[col], errors='raise')\n",
    "        except Exception as e:\n",
    "            # Imprimir un mensaje de error y eliminar la columna si falla\n",
    "            print(f'[ERROR] al convertir la columna {col} a número. {e}')\n",
    "            numeric_df.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    return numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d91a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"\n",
    "    Genera una matriz de correlación con un mapa de calor.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame con los datos.\n",
    "    \"\"\"\n",
    "    df = df.loc[:, (df != df.iloc[0]).any()]\n",
    "    correlation_matrix = df.corr()\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Parte superior (cambiar a np.tril para inferior)\n",
    "\n",
    "    print('Be aware that columns with constant values will not be plot.')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = df.corr()\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', mask=mask)\n",
    "    plt.title(\"Matriz de Correlación\")\n",
    "    plt.savefig(f'{IMAGES_PATH}/correlation_matrix.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85595fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lasso_path(X, y):\n",
    "    \"\"\"\n",
    "    Genera un gráfico del camino de Lasso para analizar la importancia de las variables.\n",
    "    \n",
    "    Args:\n",
    "        X (array-like): Variables independientes.\n",
    "        y (array-like): Variable dependiente.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X)\n",
    "    y = y.values.ravel()\n",
    "    print(\"Número de condición de X:\", np.linalg.cond(X))\n",
    "    alphas, coefs, _ = lasso_path(X_train_scaled, y, max_iter=10000, tol=1e-3)\n",
    "    print(\"Condición de X:\", np.linalg.cond(X_train_scaled))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for coef in coefs:\n",
    "        plt.plot(-np.log10(alphas), coef)\n",
    "    \n",
    "    plt.xlabel(\"-Log10(Alpha)\")\n",
    "    plt.ylabel(\"Coeficientes\")\n",
    "    plt.title(\"Lasso Path\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{IMAGES_PATH}/lasso_path.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95abf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_distribution(df):\n",
    "    \"\"\"\n",
    "    Genera gráficos de distribución para todas las columnas numéricas.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame con los datos.\n",
    "    \"\"\"\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    for column in numeric_columns:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.histplot(df[column], kde=True, bins=30)\n",
    "        plt.title(f\"Distribución de {column}\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Frecuencia\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bfa4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(X, y, feature_names):\n",
    "    \"\"\"\n",
    "    Genera un gráfico de importancia de características usando un modelo de Random Forest.\n",
    "    \n",
    "    Args:\n",
    "        X (array-like): Variables independientes.\n",
    "        y (array-like): Variable dependiente.\n",
    "        feature_names (list): Nombres de las características.\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "    model.fit(X, y)\n",
    "    importance = model.feature_importances_\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_names, importance)\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Características\")\n",
    "    plt.title(\"Importancia de las Características\")\n",
    "    plt.savefig(f'{IMAGES_PATH}/feature_importance_RF.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7762b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(X):\n",
    "    \"\"\"\n",
    "    Calcula el Factor de Inflación de la Varianza (VIF) para detectar multicolinealidad.\n",
    "    \n",
    "    Args:\n",
    "        X (DataFrame): Variables independientes.\n",
    "    \"\"\"\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a16a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns_by_file(df, file_path):\n",
    "    \"\"\"\n",
    "    Filtra las columnas del dataframe según un archivo con nombres de columnas\n",
    "    seguidos de \"OK\" o \"NO\". Las columnas con \"NO\" se eliminan.\n",
    "    \"\"\"\n",
    "    columns_to_keep = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            column_info = line.strip().split()\n",
    "            if len(column_info) == 2:  # Asegurarse de que hay un nombre y un estado\n",
    "                column_name, status = column_info\n",
    "                if status == \"OK\":\n",
    "                    columns_to_keep.append(column_name)\n",
    "\n",
    "    df_clean = df.copy()\n",
    "    return df_clean[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc05d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_icc(df, feature_col, subject_col='subject', method_col='method'):\n",
    "    \"\"\"\n",
    "    Calcula el ICC para una característica dada utilizando los modelos ICC2 e ICC3.\n",
    "    \n",
    "    Parámetros:\n",
    "        df (pd.DataFrame): DataFrame con las mediciones.\n",
    "        feature_col (str): Nombre de la columna que contiene la característica a evaluar.\n",
    "        subject_col (str): Columna que identifica al sujeto.\n",
    "        method_col (str): Columna que identifica el método o la medición.\n",
    "    \n",
    "    Retorna:\n",
    "        dict: Diccionario con los valores de ICC2 e ICC3.\n",
    "    \"\"\"\n",
    "    icc_df = pg.intraclass_corr(data=df, targets=subject_col, raters=method_col, ratings=feature_col)\n",
    "    icc2 = icc_df.loc[icc_df['Type'] == 'ICC2', 'ICC'].values[0]\n",
    "    icc3 = icc_df.loc[icc_df['Type'] == 'ICC3', 'ICC'].values[0]\n",
    "    return {'ICC2': icc2, 'ICC3': icc3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c089e8",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31021179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cambiar los nombres de los ficheros series, ejecutar en terminal en la carpeta de inputs:\n",
    "# for file in series*.nrrd; do mv \"$file\" \"${file/series/serie}\"; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c9572",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 1 for oc\n",
      "ERROR: No such file for /Users/veramegias/Documents/Universidad/Cuarto/TFG/Segmentaciones/oc/1oc/Seg1oc/serie1oc.nrrd\n",
      "ERROR: No such file for /Users/veramegias/Documents/Universidad/Cuarto/TFG/Segmentaciones/oc/1oc/Seg1oc/oc1.nrrd\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/veramegias/Documents/Universidad/Cuarto/TFG/Segmentaciones/oc/1oc/Seg1oc/serie1oc.nrrd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(mask_path):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mERROR: No such file for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m features_image \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moriginal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m features_image[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcancer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mask_path\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m features_image[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(num)\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(image_file_path, mask_file_path, process_type)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mExtrae características radiómicas de una imagen y su máscara utilizando PyRadiomics.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Comprueba que el tamaño de las imagenes sea compatible.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load paths and images\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m image_data, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnrrd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m image \u001b[38;5;241m=\u001b[39m sitk\u001b[38;5;241m.\u001b[39mGetImageFromArray(image_data)\n\u001b[1;32m     15\u001b[0m mask_data, _ \u001b[38;5;241m=\u001b[39m nrrd\u001b[38;5;241m.\u001b[39mread(mask_file_path)\n",
      "File \u001b[0;32m~/Desktop/Code/myenv/lib/python3.9/site-packages/nrrd/reader.py:520\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, custom_field_map, index_order)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, custom_field_map: Optional[NRRDFieldMap] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, index_order: IndexOrder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[npt\u001b[38;5;241m.\u001b[39mNDArray, NRRDHeader]:\n\u001b[1;32m    487\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read a NRRD file and return the header and data\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    See :ref:`background/how-to-use:reading nrrd files` for more information on reading NRRD files.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    :meth:`write`, :meth:`read_header`, :meth:`read_data`\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    521\u001b[0m         header \u001b[38;5;241m=\u001b[39m read_header(fh, custom_field_map)\n\u001b[1;32m    522\u001b[0m         data \u001b[38;5;241m=\u001b[39m read_data(header, fh, filename, index_order)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/veramegias/Documents/Universidad/Cuarto/TFG/Segmentaciones/oc/1oc/Seg1oc/serie1oc.nrrd'"
     ]
    }
   ],
   "source": [
    "if REEXECUTE:\n",
    "    df_features = pd.DataFrame()\n",
    "\n",
    "    for num in range(1,MAX_NUM):\n",
    "        for extension in ['oc', 'ccr']:\n",
    "            if num == 36 or num == 42 and extension == 'oc':  # Excluir el fichero 36oc y 42oc\n",
    "                continue\n",
    "            print(f'Executing {num} for {extension}')\n",
    "            image_path = os.path.join(INPUT_PATH, extension, str(num)+extension, 'Seg'+str(num)+extension, 'serie'+str(num)+extension+'.nrrd')\n",
    "            mask_path = os.path.join(INPUT_PATH, extension, str(num)+extension, 'Seg'+str(num)+extension, extension+str(num)+'.nrrd')        \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f'ERROR: No such file for {image_path}')\n",
    "            if not os.path.exists(mask_path):\n",
    "                print(f'ERROR: No such file for {mask_path}')\n",
    "            features_image = extract_features(image_path, mask_path, \"original\")\n",
    "            features_image['cancer'] = 'ccr' in mask_path\n",
    "            features_image['subject'] = str(num)\n",
    "            features_image['method'] = \"original\"\n",
    "            df_features = pd.concat([df_features, pd.DataFrame([features_image])], ignore_index=True)\n",
    "    df_features.to_csv('df_features.csv', index=False)\n",
    "else:\n",
    "    df_features = pd.read_csv('df_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e924ae",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce20b0",
   "metadata": {},
   "source": [
    "# Clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features[df_features['cancer'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec746f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(f'{columns_file_text}', \"w\") as f:\n",
    "        for column in df_features.columns:\n",
    "            f.write(column + \" OK \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72ce4b",
   "metadata": {},
   "source": [
    "### Edita el documento de columnas para eliminarlas. Pon \"NO\" en las que quieras eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c234cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = filter_columns_by_file(df_features, columns_file_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = convert_columns_to_numeric(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f15e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_df_clean = df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b7372",
   "metadata": {},
   "source": [
    "# ICC process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_reseg = pd.DataFrame()\n",
    "df_features_interp = pd.DataFrame()\n",
    "for num in range(1,MAX_NUM):\n",
    "    for extension in ['oc', 'ccr']:\n",
    "        if num == 36 or num == 42 and extension == 'oc':  # Excluir el fichero 36oc y 42oc\n",
    "            continue\n",
    "        print(f'Executing {num} for {extension}')\n",
    "        image_path = os.path.join(INPUT_PATH, extension, str(num)+extension, 'Seg'+str(num)+extension, 'serie'+str(num)+extension+'.nrrd')\n",
    "        mask_path = os.path.join(INPUT_PATH, extension, str(num)+extension, 'Seg'+str(num)+extension, extension+str(num)+'.nrrd')\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f'ERROR: No such file for {image_path}')\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f'ERROR: No such file for {mask_path}')\n",
    "\n",
    "        features_reseg = extract_features(image_path, mask_path, \"resegmentation\")\n",
    "        features_interp = extract_features(image_path, mask_path, \"interpolation\")\n",
    "        features_reseg['cancer'] = mask_path.contains('ccr')\n",
    "        features_interp['cancer'] = mask_path.contains('ccr')\n",
    "        features_reseg['subject'] = str(num)\n",
    "        features_interp['subject'] = str(num)\n",
    "        features_reseg['method'] = \"resegmentation\"\n",
    "        features_interp['method'] = \"interpolation\"\n",
    "        df_features_reseg = pd.concat([df_features_reseg, pd.DataFrame([features_reseg])], ignore_index=True)\n",
    "        df_features_interp = pd.concat([df_features_interp, pd.DataFrame([features_interp])], ignore_index=True)\n",
    "\n",
    "def analyze_icc(df_original, df_reseg, df_interp):\n",
    "    \"\"\"\n",
    "    Integra tres DataFrames (original, resegmentación e interpolación), \n",
    "    asigna una etiqueta a cada uno y calcula el ICC para cada característica.\n",
    "    \n",
    "    Parámetros:\n",
    "        df_original (pd.DataFrame): DataFrame con las features de la imagen original.\n",
    "        df_reseg (pd.DataFrame): DataFrame con las features tras resegmentación.\n",
    "        df_interp (pd.DataFrame): DataFrame con las features tras interpolación/muestreo.\n",
    "    \n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame en el que cada fila corresponde a una característica\n",
    "                      y se muestran los valores de ICC2 e ICC3.\n",
    "    \"\"\"\n",
    "    df_all = pd.concat([df_original, df_reseg, df_interp], ignore_index=True)\n",
    "    features_list = [col for col in df_all.columns if col not in ['subject', 'method']]\n",
    "    \n",
    "    results = {}\n",
    "    for feat in features_list:\n",
    "        results[feat] = compute_icc(df_all, feat, subject_col='subject', method_col='method')\n",
    "    return pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "results_icc = analyze_icc(df_features, df_features_reseg, df_features_interp)\n",
    "print(\"Resultados del ICC para cada característica:\")\n",
    "print(results_icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58526d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
